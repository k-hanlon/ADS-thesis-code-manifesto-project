{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MP q_sentence data and the party split info\n",
    "corpus_df = pd.read_csv(\"data/english_annotated_full_df.csv\") # full df or reduced df?\n",
    "split_df = pd.read_csv(\"data/party_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index of the corpus_df and save it as a column. This way we can always find and compare q_sentences later on\n",
    "corpus_df = corpus_df.reset_index(names=\"original_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some q_sentences are very long (and don't follow the rules of max. 1 sentence)\n",
    "# this will be a problem for the max token input of roBERTa of 512 (esp. for the context model)\n",
    "# we we will remove all q_sentences that have 100 or more words\n",
    "#  these are 96 q_sentences in total, so not very many\n",
    "corpus_df = corpus_df[corpus_df[\"q_sentence_words\"] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df[\"left_right\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df[\"green\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NAs in left_right with \"Unknown\"\n",
    "split_df['left_right'] = split_df['left_right'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode the columns\n",
    "# LEFT = 1, CENTER = 0, RIGHT = 2, Unknown = -1 --> similar to RILE coding in the corpus_dfs\n",
    "left_right_dict = {\"Far-left\": 1,\n",
    "                   \"Left\": 1,\n",
    "                   \"Center-left\": 1,\n",
    "                   \"Center\": 0,\n",
    "                   \"Center-right\": 2,\n",
    "                   \"Right\": 2,\n",
    "                   \"Unknown\": -1}\n",
    "split_df = split_df.assign(left_right  = split_df.left_right.map(left_right_dict))\n",
    "\n",
    "# Green = 1\n",
    "green_dict = {\"Yes\": 1,\n",
    "              \"No\": 0}\n",
    "split_df = split_df.assign(green  = split_df.green.map(green_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df[\"left_right\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge left_right to the corpus_df:\n",
    "corpus_df = corpus_df.merge(split_df, on=\"manifesto_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a binary label column for green codes (so code 501 is 1, rest is 0)\n",
    "corpus_df[\"green_code\"] = [1 if x == 501 else 0 for x in corpus_df[\"main_codes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all green parties:\n",
    "corpus_df[corpus_df[\"green\"] == 1][\"partyname_x\"].unique() # careful, two different parties are named \"Green Party\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left-Right Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this removes the 4 \"unknown\" parties\n",
    "left_df = corpus_df[corpus_df[\"left_right\"] == 1]\n",
    "right_df = corpus_df[corpus_df[\"left_right\"] == 2]\n",
    "center_df = corpus_df[corpus_df[\"left_right\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are top frequent codes for the different sets? How many R/L/N are there in RILE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(left_df[\"main_codes\"].value_counts()/(left_df.shape[0]))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df[\"RILE\"].value_counts()/left_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(right_df[\"main_codes\"].value_counts()/(right_df.shape[0]))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_df[\"RILE\"].value_counts()/right_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(center_df[\"main_codes\"].value_counts()/(center_df.shape[0]))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_df[\"RILE\"].value_counts()/center_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns do we need in the data for the model?\n",
    "relevant_cols = [\"q_sentence\", \"q_sentence_nr\", \"manifesto_id\", \"main_codes\", \"RILE\", \"original_index\"]\n",
    "left_df = left_df[relevant_cols]\n",
    "right_df = right_df[relevant_cols]\n",
    "center_df = center_df[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left as train\n",
    "# train: 70% Left\n",
    "# validation: 15% Left\n",
    "# test: 15% Left\n",
    "# inference_right: 100% Right\n",
    "# inference_center: 100% Center\n",
    "\n",
    "# split on manifestos:\n",
    "manifesto_ids = left_df[\"manifesto_id\"].unique()\n",
    "np.random.seed(6) # keep it reproducible (and so that ca. 10% of the q_sentences land in the validation set)\n",
    "np.random.shuffle(manifesto_ids)\n",
    "\n",
    "# select manifestos into the different sets (so that about 15% of q_sentences are in the validation and test sets, see below)\n",
    "train_manifesto_ids = manifesto_ids[28:] # 10 manifestos\n",
    "val_manifesto_ids = manifesto_ids[:13] # 13\n",
    "test_manifesto_ids = manifesto_ids[13:28] # 7 manifestos\n",
    "\n",
    "train_df = left_df[left_df[\"manifesto_id\"].isin(train_manifesto_ids)]\n",
    "val_df = left_df[left_df[\"manifesto_id\"].isin(val_manifesto_ids)]\n",
    "test_df = left_df[left_df[\"manifesto_id\"].isin(test_manifesto_ids)]\n",
    "inference_right_df = right_df.copy()\n",
    "inference_center_df = center_df.copy()\n",
    "\n",
    "print(\"Number of q_sentences in the training set:\", train_df.shape[0])\n",
    "print(\"Number of q_sentences in the validation set:\", val_df.shape[0])\n",
    "print(\"Number of q_sentences in the test set:\", test_df.shape[0])\n",
    "print(\"Percentage of the train set:\", train_df.shape[0]/left_df.shape[0])\n",
    "print(\"Percentage of the validation set:\", val_df.shape[0]/left_df.shape[0])\n",
    "print(\"Percentage of the test set:\", test_df.shape[0]/left_df.shape[0])\n",
    "\n",
    "# make sure they are sorted correctly (important for adding the context later on)\n",
    "train_df = train_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "val_df = val_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "test_df = test_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_right_df = inference_right_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_center_df = inference_center_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "\n",
    "# and reset the indicies\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "inference_right_df.reset_index(drop=True, inplace=True)\n",
    "inference_center_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# and now save them as csv so that they can be loaded into huggingface\n",
    "# train_df.to_csv(\"data/model_splits/left_right_split/left_as_train/train-00000-of-00001.csv\", index=False)\n",
    "# val_df.to_csv(\"data/model_splits/left_right_split/left_as_train/validation-00000-of-00001.csv\", index=False)\n",
    "# test_df.to_csv(\"data/model_splits/left_right_split/left_as_train/test-00000-of-00001.csv\", index=False)\n",
    "# inference_right_df.to_csv(\"data/model_splits/left_right_split/left_as_train/inference_right-00000-of-00001.csv\", index=False)\n",
    "# inference_center_df.to_csv(\"data/model_splits/left_right_split/left_as_train/inference_center-00000-of-00001.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manifesto_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RILE proportions in train:\\n\", train_df[\"RILE\"].value_counts()/train_df.shape[0])\n",
    "print(\"\\nRILE proportions in validation:\\n\", val_df[\"RILE\"].value_counts()/val_df.shape[0])\n",
    "print(\"\\nRILE proportions in test:\\n\", test_df[\"RILE\"].value_counts()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRILE proportions in inference right:\\n\", inference_right_df[\"RILE\"].value_counts()/inference_right_df.shape[0])\n",
    "print(\"\\nRILE proportions in inference center:\\n\", inference_center_df[\"RILE\"].value_counts()/inference_center_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right as train\n",
    "# train: 70% right\n",
    "# validation: 15% right\n",
    "# test: 15% right\n",
    "# inference_left: 100% Left\n",
    "# inference_center: 100% Center\n",
    "\n",
    "# split on manifestos:\n",
    "manifesto_ids = right_df[\"manifesto_id\"].unique()\n",
    "np.random.seed(19) # keep it reproducible (and so that ca. 10% of the q_sentences land in the validation set)\n",
    "np.random.shuffle(manifesto_ids)\n",
    "\n",
    "# select manifestos into the different sets (so that about 15% of q_sentences are in the validation and test sets, see below)\n",
    "train_manifesto_ids = manifesto_ids[26:] #\n",
    "val_manifesto_ids = manifesto_ids[:13] #\n",
    "test_manifesto_ids = manifesto_ids[13:26] #\n",
    "\n",
    "train_df = right_df[right_df[\"manifesto_id\"].isin(train_manifesto_ids)]\n",
    "val_df = right_df[right_df[\"manifesto_id\"].isin(val_manifesto_ids)]\n",
    "test_df = right_df[right_df[\"manifesto_id\"].isin(test_manifesto_ids)]\n",
    "inference_left_df = left_df.copy()\n",
    "inference_center_df = center_df.copy()\n",
    "\n",
    "print(\"Number of q_sentences in the training set:\", train_df.shape[0])\n",
    "print(\"Number of q_sentences in the validation set:\", val_df.shape[0])\n",
    "print(\"Number of q_sentences in the test set:\", test_df.shape[0])\n",
    "print(\"Percentage of the train set:\", train_df.shape[0]/right_df.shape[0])\n",
    "print(\"Percentage of the validation set:\", val_df.shape[0]/right_df.shape[0])\n",
    "print(\"Percentage of the test set:\", test_df.shape[0]/right_df.shape[0])\n",
    "\n",
    "# make sure they are sorted correctly (important for adding the context later on)\n",
    "train_df = train_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "val_df = val_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "test_df = test_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_left_df = inference_left_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_center_df = inference_center_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "\n",
    "# and reset the indicies\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "inference_left_df.reset_index(drop=True, inplace=True)\n",
    "inference_center_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# and now save them as csv so that they can be loaded into huggingface\n",
    "# train_df.to_csv(\"data/model_splits/left_right_split/right_as_train/train-00000-of-00001.csv\", index=False)\n",
    "# val_df.to_csv(\"data/model_splits/left_right_split/right_as_train/validation-00000-of-00001.csv\", index=False)\n",
    "# test_df.to_csv(\"data/model_splits/left_right_split/right_as_train/test-00000-of-00001.csv\", index=False)\n",
    "# inference_left_df.to_csv(\"data/model_splits/left_right_split/right_as_train/inference_left-00000-of-00001.csv\", index=False)\n",
    "# inference_center_df.to_csv(\"data/model_splits/left_right_split/right_as_train/inference_center-00000-of-00001.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manifesto_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RILE proportions in train:\\n\", train_df[\"RILE\"].value_counts()/train_df.shape[0])\n",
    "print(\"\\nRILE proportions in validation:\\n\", val_df[\"RILE\"].value_counts()/val_df.shape[0])\n",
    "print(\"\\nRILE proportions in test:\\n\", test_df[\"RILE\"].value_counts()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRILE proportions in inference left:\\n\", inference_left_df[\"RILE\"].value_counts()/inference_left_df.shape[0])\n",
    "print(\"\\nRILE proportions in inference center:\\n\", inference_center_df[\"RILE\"].value_counts()/inference_center_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Green Split\n",
    "Creating Training data based on non-green parties (and an inference set with the green parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df[\"green\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_df = corpus_df[corpus_df[\"green\"] == 1]\n",
    "other_df = corpus_df[corpus_df[\"green\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns do we need in the data for the model?\n",
    "relevant_cols = [\"q_sentence\", \"q_sentence_nr\", \"manifesto_id\", \"main_codes\", \"green_code\", \"original_index\"]\n",
    "green_df = green_df[relevant_cols]\n",
    "other_df = other_df[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# green as train\n",
    "# train: 70% Green\n",
    "# validation: 15% Green\n",
    "# test: 15% Green\n",
    "# inference: 100% non-Green\n",
    "\n",
    "# split on manifestos:\n",
    "manifesto_ids = green_df[\"manifesto_id\"].unique()\n",
    "np.random.seed(13) # keep it reproducible (and so that ca. 10% of the q_sentences land in the validation set)\n",
    "np.random.shuffle(manifesto_ids)\n",
    "\n",
    "# select manifestos into the different sets (so that about 15% of q_sentences are in the validation and test sets, see below)\n",
    "train_manifesto_ids = manifesto_ids[10:] # 10 manifestos\n",
    "val_manifesto_ids = manifesto_ids[:3] # this is 3 manifestos\n",
    "test_manifesto_ids = manifesto_ids[3:10] # 7 manifestos\n",
    "\n",
    "train_df = green_df[green_df[\"manifesto_id\"].isin(train_manifesto_ids)]\n",
    "val_df = green_df[green_df[\"manifesto_id\"].isin(val_manifesto_ids)]\n",
    "test_df = green_df[green_df[\"manifesto_id\"].isin(test_manifesto_ids)]\n",
    "inference_df = other_df.copy()\n",
    "\n",
    "print(\"Number of q_sentences in the training set:\", train_df.shape[0])\n",
    "print(\"Number of q_sentences in the validation set:\", val_df.shape[0])\n",
    "print(\"Number of q_sentences in the test set:\", test_df.shape[0])\n",
    "print(\"Percentage of the train set:\", train_df.shape[0]/green_df.shape[0])\n",
    "print(\"Percentage of the validation set:\", val_df.shape[0]/green_df.shape[0])\n",
    "print(\"Percentage of the test set:\", test_df.shape[0]/green_df.shape[0])\n",
    "\n",
    "# make sure they are sorted correctly (important for adding the context later on)\n",
    "train_df = train_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "val_df = val_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "test_df = test_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_df = inference_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "\n",
    "# and reset the indicies\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "inference_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# and now save them as csv so that they can be loaded into huggingface\n",
    "# train_df.to_csv(\"data/model_splits/green_split/green_as_train/train-00000-of-00001.csv\", index=False)\n",
    "# val_df.to_csv(\"data/model_splits/green_split/green_as_train/validation-00000-of-00001.csv\", index=False)\n",
    "# test_df.to_csv(\"data/model_splits/green_split/green_as_train/test-00000-of-00001.csv\", index=False)\n",
    "# inference_df.to_csv(\"data/model_splits/green_split/green_as_train/inference-00000-of-00001.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manifesto_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of green codes in train: \", sum(train_df[\"green_code\"])/train_df.shape[0])\n",
    "print(\"Percentage of green codes in validation: \", sum(val_df[\"green_code\"])/val_df.shape[0])\n",
    "print(\"Percentage of green codes in test: \", sum(test_df[\"green_code\"])/test_df.shape[0])\n",
    "print(\"Percentage of green codes in inference: \", sum(inference_df[\"green_code\"])/inference_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-green as train\n",
    "# train: 70% non-Green\n",
    "# validation: 15% non-Green\n",
    "# test: 15% non-Green\n",
    "# inference: 100% Green\n",
    "\n",
    "# split on manifestos:\n",
    "manifesto_ids = other_df[\"manifesto_id\"].unique()\n",
    "np.random.seed(0) # keep it reproducible (and so that ca. 10% of the q_sentences land in the validation set)\n",
    "np.random.shuffle(manifesto_ids)\n",
    "\n",
    "# select manifestos into the different sets (so that about 15% of q_sentences are in the validation and test sets, see below)\n",
    "train_manifesto_ids = manifesto_ids[56:] # \n",
    "val_manifesto_ids = manifesto_ids[:28] # \n",
    "test_manifesto_ids = manifesto_ids[28:56] # \n",
    "\n",
    "train_df = other_df[other_df[\"manifesto_id\"].isin(train_manifesto_ids)]\n",
    "val_df = other_df[other_df[\"manifesto_id\"].isin(val_manifesto_ids)]\n",
    "test_df = other_df[other_df[\"manifesto_id\"].isin(test_manifesto_ids)]\n",
    "inference_df = green_df.copy()\n",
    "\n",
    "print(\"Number of q_sentences in the training set:\", train_df.shape[0])\n",
    "print(\"Number of q_sentences in the validation set:\", val_df.shape[0])\n",
    "print(\"Number of q_sentences in the test set:\", test_df.shape[0])\n",
    "print(\"Percentage of the train set:\", train_df.shape[0]/other_df.shape[0])\n",
    "print(\"Percentage of the validation set:\", val_df.shape[0]/other_df.shape[0])\n",
    "print(\"Percentage of the test set:\", test_df.shape[0]/other_df.shape[0])\n",
    "\n",
    "# make sure they are sorted correctly (important for adding the context later on)\n",
    "train_df = train_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "val_df = val_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "test_df = test_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_df = inference_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "\n",
    "# and reset the indicies\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "inference_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# and now save them as csv so that they can be loaded into huggingface\n",
    "# train_df.to_csv(\"data/model_splits/green_split/non_green_as_train/train-00000-of-00001.csv\", index=False)\n",
    "# val_df.to_csv(\"data/model_splits/green_split/non_green_as_train/validation-00000-of-00001.csv\", index=False)\n",
    "# test_df.to_csv(\"data/model_splits/green_split/non_green_as_train/test-00000-of-00001.csv\", index=False)\n",
    "# inference_df.to_csv(\"data/model_splits/green_split/non_green_as_train/inference-00000-of-00001.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manifesto_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of green codes in train: \", sum(train_df[\"green_code\"])/train_df.shape[0])\n",
    "print(\"Percentage of green codes in validation: \", sum(val_df[\"green_code\"])/val_df.shape[0])\n",
    "print(\"Percentage of green codes in test: \", sum(test_df[\"green_code\"])/test_df.shape[0])\n",
    "print(\"Percentage of green codes in inference: \", sum(inference_df[\"green_code\"])/inference_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
