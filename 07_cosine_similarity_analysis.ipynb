{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare and analyze the cosine similarity results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to do with this? Generate examples for all!\n",
    "\n",
    "# Look at examples, what is our cos sim threshold?\n",
    "# Remove where both are -1? and both are 0?\n",
    "# Which codes appear most often?\n",
    "# Which codes appear most often when agreement?\n",
    "# Which codes appear most often in disagreement?\n",
    "# Look at sentences that are exactly the same: how often is there disagreement?\n",
    "# What changes if we limit to combinations by different coders/from different documents?\n",
    "# in 0/-1 codes: how often do coders agree, that there is no meaning in this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show full contents of each column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# reverse with:\n",
    "# pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sparse matrix with the extreme similarity values:\n",
    "cs_sparse = load_npz('data/cos_sim_output_08_mpnet.npz')\n",
    "\n",
    "# also load the full corpus df, so that we can add create a df with q_sentences, information and their similarity score for extreme values\n",
    "corpus_df_full = pd.read_csv(\"data/english_annotated_full_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sparse matrix into a useful df:\n",
    "cs_sparse = coo_matrix(cs_sparse)\n",
    "data = {\n",
    "    'index_x': cs_sparse.row,\n",
    "    'index_y': cs_sparse.col,\n",
    "    'cosine_similarity': cs_sparse.data\n",
    "}\n",
    "cosine_sim_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = corpus_df_full[['q_sentence', \"q_sentence_nr\", 'main_codes', 'coderid', 'manifesto_id', 'party', 'date',\n",
    "        'title', 'countryname', 'partyname', 'RILE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the columns from the corpus_df, so that we get the info for both quasi sentences\n",
    "cosine_sim_df = pd.merge(cosine_sim_df, corpus_df, left_on='index_x', right_index=True, how='left')\n",
    "cosine_sim_df = pd.merge(cosine_sim_df, corpus_df, left_on='index_y', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many values do we have that are below -0.8?\n",
    "cosine_sim_df[cosine_sim_df[\"cosine_similarity\"] < 0].shape\n",
    "# --> none of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the lowest cosine similarities. Are they good enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_sim_df.sort_values(by=\"cosine_similarity\",\n",
    "#                           ascending=True)[[\"q_sentence_x\", \"main_codes_x\", \"q_sentence_y\", \"main_codes_y\", \"cosine_similarity\"]].head(20)\n",
    "\n",
    "cosine_sim_df.sort_values(by=\"cosine_similarity\",\n",
    "                          ascending=True)[[\"manifesto_id_x\", \"q_sentence_nr_x\", \"q_sentence_x\", \"q_sentence_y\", \"manifesto_id_y\", \"q_sentence_nr_y\", \"cosine_similarity\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, they look very good! (We could even think about lowering the threshold in the calculation script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General overview: how often do codes appear? How often in agreement / disagreement?\n",
    "This is done here before removing certain combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just simple: how often are the same codes given?\n",
    "cosine_sim_df[cosine_sim_df[\"main_codes_x\"] == cosine_sim_df[\"main_codes_y\"]].shape[0]/cosine_sim_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = np.union1d(cosine_sim_df[\"main_codes_x\"].unique(), cosine_sim_df[\"main_codes_y\"].unique())\n",
    "total_counts = dict()\n",
    "agreement_counts = dict()\n",
    "disagreement_counts = dict()\n",
    "\n",
    "for c in codes:\n",
    "    count = ((cosine_sim_df['main_codes_x'] == c) | (cosine_sim_df['main_codes_y'] == c)).sum()\n",
    "    total_counts[c] = count\n",
    "    \n",
    "    count = ((cosine_sim_df['main_codes_x'] == c) & (cosine_sim_df['main_codes_y'] == c)).sum()\n",
    "    agreement_counts[c] = count\n",
    "\n",
    "    count = ((cosine_sim_df['main_codes_x'] != c) ^ (cosine_sim_df['main_codes_y'] != c)).sum()\n",
    "    disagreement_counts[c] = count\n",
    "\n",
    "# Create a dictionary with the percentage of disagreement for this code\n",
    "# so disagreement_count/total_count\n",
    "perc_dict = dict()\n",
    "for k,v in total_counts.items():\n",
    "    perc_dict[k] = disagreement_counts[k]/v\n",
    "\n",
    "# Getting the dicts into a df:\n",
    "\n",
    "merged_df = pd.merge(pd.DataFrame(list(total_counts.items()), columns=['code', 'total_counts']),\n",
    "                     pd.DataFrame(list(perc_dict.items()), columns=['code', 'perc_disagree']),\n",
    "                     on='code')\n",
    "\n",
    "merged_df_temp = pd.merge(pd.DataFrame(list(agreement_counts.items()), columns=['code', 'agreement_counts']),\n",
    "                     pd.DataFrame(list(disagreement_counts.items()), columns=['code', 'disagreement_counts']),\n",
    "                     on='code')\n",
    "\n",
    "code_combinations_df_full = pd.merge(merged_df, merged_df_temp, on='code')\n",
    "\n",
    "# add the percentage how often a code appears in the similar sentence combinations:\n",
    "code_combinations_df_full[\"perc_total_occurance\"] = code_combinations_df_full[\"total_counts\"]/cosine_sim_df.shape[0]\n",
    "\n",
    "code_combinations_df_full.sort_values(by=\"perc_total_occurance\", ascending=False, inplace=True)\n",
    "code_combinations_df_full.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the most occuring codes:\n",
    "top_ten_codes = code_combinations_df_full.head(10)[\"code\"].astype(str)\n",
    "top_ten_percentages = code_combinations_df_full.head(10)[\"perc_total_occurance\"]\n",
    "\n",
    "plt.bar(top_ten_codes, top_ten_percentages)\n",
    "\n",
    "plt.xlabel('Code')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Most occuring codes in similar quasi-sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often do coders agree that similar sentences have no content/useful meaning? So how often do both give 0 or -1? How often does only one give 0 or -1?\n",
    "\n",
    "# How often does either -1 or 0 appear in one or both of the codes:\n",
    "count_a = cosine_sim_df[(((cosine_sim_df['main_codes_x'] == -1) | (cosine_sim_df['main_codes_x'] == 0)) | (\n",
    "    (cosine_sim_df['main_codes_y'] == -1) | (cosine_sim_df['main_codes_y'] == 0)))].shape[0]\n",
    "\n",
    "# How often do both codes have either -1 or 0:\n",
    "count_b = cosine_sim_df[(((cosine_sim_df['main_codes_x'] == -1) | (cosine_sim_df['main_codes_x'] == 0)) & (\n",
    "    (cosine_sim_df['main_codes_y'] == -1) | (cosine_sim_df['main_codes_y'] == 0)))].shape[0]\n",
    "\n",
    "# How often does only one code have either -1 or 0:\n",
    "count_c = cosine_sim_df[(((cosine_sim_df['main_codes_x'] == -1) | (cosine_sim_df['main_codes_x'] == 0)) ^ (\n",
    "    (cosine_sim_df['main_codes_y'] == -1) | (cosine_sim_df['main_codes_y'] == 0)))].shape[0]\n",
    "\n",
    "# So, how often do coders disagree on these?\n",
    "print(count_c/count_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_b/cosine_sim_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the percentage of all combinations?\n",
    "print(count_c/cosine_sim_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"Only one -1/0\", \"Both -1/0\"]\n",
    "y = [count_c/count_a, 1-count_c/count_a]\n",
    "\n",
    "plt.bar(x, y)\n",
    "\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('How often do both codes contain -1 or 0?')\n",
    "\n",
    "# Annotate the bars with their corresponding values\n",
    "for i in range(len(x)):\n",
    "    plt.text(i, y[i], f'{y[i]*100:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> In about 91% of the time, coders agree if there is no meaning in a q_sentence. 9% of the time, one of them sees a meaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing rows where coders agree on -1 or 0 (so that this q_sentence has no \"meaning\" per se):\n",
    "\n",
    "This removes 251.679 combinations, or 66.3% of all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows where both codes are -1; here the coders agree that it is not a topic that needs to be coded, likely just formating etc.\n",
    "#cosine_sim_df = cosine_sim_df[(cosine_sim_df['main_codes_x'] != -1) | (cosine_sim_df['main_codes_y'] != -1)]\n",
    "# same thing for both codes 0\n",
    "#cosine_sim_df = cosine_sim_df[(cosine_sim_df['main_codes_x'] != 0) | (cosine_sim_df['main_codes_y'] != 0)]\n",
    "\n",
    "\n",
    "# and now also where one is -1 and one is 0: the coders agree, there is no meaning in this\n",
    "\n",
    "# This does it all in one: removes all rows where both codes are either 0 or -1:\n",
    "cosine_sim_df = cosine_sim_df[~(((cosine_sim_df['main_codes_x'] == -1) | (cosine_sim_df['main_codes_x'] == 0)) & (\n",
    "    (cosine_sim_df['main_codes_y'] == -1) | (cosine_sim_df['main_codes_y'] == 0)))]\n",
    "\n",
    "\n",
    "cosine_sim_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often do coders disagree on these similar sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column that indicates if coders agreed\n",
    "cosine_sim_df[\"in_agreement\"] = cosine_sim_df['main_codes_x'] == cosine_sim_df['main_codes_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often are codes not equal?\n",
    "1 - sum(cosine_sim_df[\"in_agreement\"])/cosine_sim_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df[cosine_sim_df[\"cosine_similarity\"] > 0.975][[\"coderid_x\", \"manifesto_id_x\", \"q_sentence_nr_x\", \"q_sentence_x\", \"main_codes_x\",\n",
    "                                                           \"q_sentence_y\", \"main_codes_y\", \"manifesto_id_y\", \"q_sentence_nr_y\", \"coderid_y\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often do coders agree on the same codes? Does this change as the cosine similarity increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins for column A\n",
    "plot_df = cosine_sim_df.copy()\n",
    "\n",
    "bins = [0.8, 0.825, 0.85, 0.875, 0.9, 0.925, 0.95, 0.975, 1.0]\n",
    "\n",
    "# Create a new column 'Bin' which indicates the bin that each value in column A falls into\n",
    "plot_df['Bin'] = pd.cut(plot_df['cosine_similarity'], bins)\n",
    "\n",
    "# Calculate the percentage of True values in each bin\n",
    "bin_percentages = plot_df.groupby('Bin')['in_agreement'].mean() * 100\n",
    "\n",
    "# Create a bar plot\n",
    "bars = plt.bar(bin_percentages.index.astype(str), bin_percentages, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add percentage labels above the bars\n",
    "for bar, percentage in zip(bars, bin_percentages):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{percentage:.1f}%', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Percentage of combinations with the same code')\n",
    "plt.title('How often do coders agree on the same codes?')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility\n",
    "# Add '%' sign to the y-axis labels\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x) for x in plt.gca().get_yticks()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = cosine_sim_df.copy()\n",
    "plot_df = plot_df[cosine_sim_df[\"manifesto_id_x\"] != cosine_sim_df[\"manifesto_id_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does this change if we only take combinations of different documents?\n",
    "# (So coders dont just pick the same code for the sentence they see again and again?)\n",
    "\n",
    "# Define the bins for column A\n",
    "plot_df = cosine_sim_df.copy()\n",
    "# remove combinations from the same document:\n",
    "plot_df = plot_df[cosine_sim_df[\"manifesto_id_x\"] != cosine_sim_df[\"manifesto_id_y\"]]\n",
    "print(plot_df.shape)\n",
    "\n",
    "bins = [0.8, 0.825, 0.85, 0.875, 0.9, 0.925, 0.95, 0.975, 1.0]\n",
    "\n",
    "# Create a new column 'Bin' which indicates the bin that each value in column A falls into\n",
    "plot_df['Bin'] = pd.cut(plot_df['cosine_similarity'], bins)\n",
    "\n",
    "# Calculate the percentage of True values in each bin\n",
    "bin_percentages = plot_df.groupby('Bin')['in_agreement'].mean() * 100\n",
    "\n",
    "# Create a bar plot\n",
    "bars = plt.bar(bin_percentages.index.astype(str), bin_percentages, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add percentage labels above the bars\n",
    "for bar, percentage in zip(bars, bin_percentages):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{percentage:.1f}%', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Percentage of codes in agreement')\n",
    "plt.title('How often do coders agree on the same codes?\\nOnly looking at combinations from different manifestos')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility\n",
    "# Add '%' sign to the y-axis labels\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x) for x in plt.gca().get_yticks()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having a look at certain cosine similarity ranges:\n",
    "\n",
    "cosine_sim_df[(cosine_sim_df['cosine_similarity'] >= 0.95) & (cosine_sim_df['cosine_similarity'] <= 0.975)].head(10)[[\"coderid_x\", \"manifesto_id_x\", \"q_sentence_nr_x\", \"q_sentence_x\", \"main_codes_x\",\n",
    "                                                           \"q_sentence_y\", \"main_codes_y\", \"manifesto_id_y\", \"q_sentence_nr_y\", \"coderid_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df[(cosine_sim_df['cosine_similarity'] >= 0.975) & (cosine_sim_df['cosine_similarity'] <= 1.1)].head(10)[[\"cosine_similarity\",\"coderid_x\", \"manifesto_id_x\", \"q_sentence_nr_x\", \"q_sentence_x\", \"main_codes_x\",\n",
    "                                                           \"q_sentence_y\", \"main_codes_y\", \"manifesto_id_y\", \"q_sentence_nr_y\", \"coderid_y\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which codes appear most often? Which most often in agreement? Which most often when not in agreement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = np.union1d(cosine_sim_df[\"main_codes_x\"].unique(), cosine_sim_df[\"main_codes_y\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = dict()\n",
    "agreement_counts = dict()\n",
    "disagreement_counts = dict()\n",
    "domain_agreement_counts = dict()\n",
    "domain_disagreement_counts = dict()\n",
    "\n",
    "for c in codes:\n",
    "    count = ((cosine_sim_df['main_codes_x'] == c) | (cosine_sim_df['main_codes_y'] == c)).sum()\n",
    "    total_counts[c] = count\n",
    "    \n",
    "    count = ((cosine_sim_df['main_codes_x'] == c) & (cosine_sim_df['main_codes_y'] == c)).sum()\n",
    "    agreement_counts[c] = count\n",
    "\n",
    "    count = ((cosine_sim_df['main_codes_x'] != c) ^ (cosine_sim_df['main_codes_y'] != c)).sum()\n",
    "    disagreement_counts[c] = count\n",
    "\n",
    "    domain = str(c)[0]\n",
    "    # select all rows where one of the codes is c and both start with the same number as c:\n",
    "    count = cosine_sim_df[((cosine_sim_df[\"main_codes_x\"] == c) | (cosine_sim_df[\"main_codes_y\"] == c)) &\n",
    "                ((cosine_sim_df[\"main_codes_x\"].astype(str).str[0] == domain)\n",
    "                & (cosine_sim_df[\"main_codes_y\"].astype(str).str[0] == domain))].shape[0]\n",
    "    domain_agreement_counts[c] = count\n",
    "\n",
    "    # select all rows where one of the codes is c and one is from a different domain:\n",
    "    count = cosine_sim_df[((cosine_sim_df[\"main_codes_x\"] == c) | (cosine_sim_df[\"main_codes_y\"] == c)) &\n",
    "                ~((cosine_sim_df[\"main_codes_x\"].astype(str).str[0] == domain)\n",
    "                & (cosine_sim_df[\"main_codes_y\"].astype(str).str[0] == domain))].shape[0]\n",
    "    domain_disagreement_counts[c] = count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the percentage of disagreement for this code\n",
    "# so disagreement_count/total_count\n",
    "# also for domain disagreement\n",
    "\n",
    "perc_dict = dict()\n",
    "domain_perc_dict = dict()\n",
    "for k,v in total_counts.items():\n",
    "    perc_dict[k] = disagreement_counts[k]/v\n",
    "    domain_perc_dict[k] = domain_disagreement_counts[k]/v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dicts into a df:\n",
    "merged_df = pd.merge(pd.DataFrame(list(total_counts.items()), columns=['code', 'total_counts']),\n",
    "                     pd.DataFrame(list(perc_dict.items()), columns=['code', 'perc_disagree']),\n",
    "                     on='code')\n",
    "\n",
    "merged_df_temp = pd.merge(pd.DataFrame(list(agreement_counts.items()), columns=['code', 'agreement_counts']),\n",
    "                     pd.DataFrame(list(disagreement_counts.items()), columns=['code', 'disagreement_counts']),\n",
    "                     on='code')\n",
    "\n",
    "code_combinations_df = pd.merge(merged_df, merged_df_temp, on='code')\n",
    "\n",
    "merged_df_temp_2 = pd.merge(pd.DataFrame(list(domain_agreement_counts.items()), columns=['code', 'domain_agreement_counts']),\n",
    "                     pd.DataFrame(list(domain_disagreement_counts.items()), columns=['code', 'domain_disagreement_counts']),\n",
    "                     on='code')\n",
    "\n",
    "merged_df_temp_3 = pd.merge(merged_df_temp_2,\n",
    "                            pd.DataFrame(list(domain_perc_dict.items()), columns=['code', 'domain_perc_disagree']),\n",
    "                            on='code' )\n",
    "\n",
    "code_combinations_df = pd.merge(code_combinations_df, merged_df_temp_3, on = \"code\")\n",
    "\n",
    "# add the percentage how often a code appears in the similar sentence combinations:\n",
    "code_combinations_df[\"perc_total_occurance\"] = code_combinations_df[\"total_counts\"]/cosine_sim_df.shape[0]\n",
    "\n",
    "code_combinations_df.sort_values(by=\"perc_total_occurance\", ascending=False, inplace=True)\n",
    "\n",
    "code_combinations_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_combinations_df[code_combinations_df[\"code\"] == 702]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_combinations_df[code_combinations_df[\"perc_disagree\"] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example for 408\n",
    "#cosine_sim_df[(cosine_sim_df[\"main_codes_x\"] == 408) & (cosine_sim_df[\"main_codes_y\"] != 408)].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing if the numbers make sense\n",
    "#cosine_sim_df[(cosine_sim_df[\"main_codes_x\"] == 702) & (cosine_sim_df[\"main_codes_y\"] == 702)].shape\n",
    "# total counts is all combinations * 2 (as each comb has two codes) - the number of combinations that are in agreement (as here only one code appears)\n",
    "sum(code_combinations_df[\"total_counts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.shape[0]*2 - sum(code_combinations_df[\"agreement_counts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the most occuring codes:\n",
    "code_combinations_df.sort_values(by=\"perc_total_occurance\", ascending=False, inplace=True)\n",
    "\n",
    "top_ten_codes = code_combinations_df.head(20)[\"code\"].astype(str)\n",
    "top_ten_percentages = code_combinations_df.head(20)[\"perc_total_occurance\"]\n",
    "\n",
    "plt.bar(top_ten_codes, top_ten_percentages)\n",
    "\n",
    "plt.xlabel('Codes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of combinations that contain this code (top 20)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar thing, but sorted by codes that are the most contentious:\n",
    "code_combinations_df.sort_values(by=\"perc_disagree\", ascending=False, inplace=True)\n",
    "\n",
    "# Plot the most occuring codes:\n",
    "top_ten_codes = code_combinations_df.head(20)[\"code\"].astype(str)\n",
    "top_ten_percentages = code_combinations_df.head(20)[\"perc_disagree\"]\n",
    "top_ten_total_counts = code_combinations_df.head(20)[\"total_counts\"]\n",
    "\n",
    "bars = plt.bar(top_ten_codes, top_ten_percentages)\n",
    "\n",
    "# Add total counts as text on top of each bar\n",
    "# for bar, count in zip(bars, top_ten_total_counts):\n",
    "#     plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "#              ha='center', va='bottom', rotation = 45)\n",
    "\n",
    "plt.xlabel('Code')\n",
    "plt.ylabel('Frequency of code occurence where\\ncombination is in disagreement')\n",
    "plt.title('Most unreliable codes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing, but sorted by codes that are the least contentious:\n",
    "code_combinations_df.sort_values(by=\"perc_disagree\", ascending=True, inplace=True)\n",
    "\n",
    "# Plot the most occuring codes:\n",
    "top_ten_codes = code_combinations_df.head(20)[\"code\"].astype(str)\n",
    "top_ten_percentages = code_combinations_df.head(20)[\"perc_disagree\"]\n",
    "top_ten_total_counts = code_combinations_df.head(20)[\"total_counts\"]\n",
    "\n",
    "bars = plt.bar(top_ten_codes, top_ten_percentages)\n",
    "\n",
    "# Add total counts as text on top of each bar\n",
    "# for bar, count in zip(bars, top_ten_total_counts):\n",
    "#     plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "#              ha='center', va='bottom', rotation = 45)\n",
    "\n",
    "plt.xlabel('Code')\n",
    "plt.ylabel('Frequency of code occurence where\\ncombination is in disagreement')\n",
    "plt.title('Most reliable codes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_combinations_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(code_combinations_df[\"code\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about getting at least the domain right? What codes actually switch domain often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing, but sorted by codes that most often change domains:\n",
    "code_combinations_df.sort_values(by=\"domain_perc_disagree\", ascending=False, inplace=True)\n",
    "\n",
    "# Plot the most occuring codes:\n",
    "x = 20\n",
    "top_ten_codes = code_combinations_df.head(x)[\"code\"].astype(str)\n",
    "top_ten_percentages = code_combinations_df.head(x)[\"domain_perc_disagree\"]\n",
    "top_ten_total_counts = code_combinations_df.head(x)[\"total_counts\"]\n",
    "\n",
    "bars = plt.bar(top_ten_codes, top_ten_percentages)\n",
    "\n",
    "# Add total counts as text on top of each bar\n",
    "for bar, count in zip(bars, top_ten_total_counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', rotation = 45)\n",
    "\n",
    "plt.xlabel('Codes')\n",
    "plt.ylabel('Occurrence')\n",
    "plt.title('Percentage of combinations that contain this code and a\\ncode from a different domain (top 20)\\nWith total occurence count on top of the bars')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing, but sorted by codes that least often change domains:\n",
    "code_combinations_df.sort_values(by=\"domain_perc_disagree\", ascending=True, inplace=True)\n",
    "\n",
    "# Plot the most occuring codes:\n",
    "top_ten_codes = code_combinations_df.head(20)[\"code\"].astype(str)\n",
    "top_ten_percentages = code_combinations_df.head(20)[\"domain_perc_disagree\"]\n",
    "top_ten_total_counts = code_combinations_df.head(20)[\"total_counts\"]\n",
    "\n",
    "bars = plt.bar(top_ten_codes, top_ten_percentages)\n",
    "\n",
    "# Add total counts as text on top of each bar\n",
    "for bar, count in zip(bars, top_ten_total_counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', rotation = 45)\n",
    "\n",
    "plt.xlabel('Codes')\n",
    "plt.ylabel('Occurrence')\n",
    "plt.title('Percentage of combinations that contain this code and a\\ncode from a different domain (bottom 20)\\nWith total occurence count on top of the bars')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_combinations_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deeper look into sentences that are exactly the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_df = cosine_sim_df[cosine_sim_df[\"q_sentence_x\"] == cosine_sim_df[\"q_sentence_y\"]]\n",
    "same_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often are the codes the same?\n",
    "same_df[same_df[\"main_codes_x\"] == same_df[\"main_codes_y\"]].shape[0]/same_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_df[[\"q_sentence_x\", \"main_codes_x\", \"q_sentence_y\", \"main_codes_y\",\n",
    "         \"cosine_similarity\"]].sort_values(by=\"cosine_similarity\", ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_tmp_df = same_df[same_df[\"main_codes_x\"] != same_df[\"main_codes_y\"]]\n",
    "same_tmp_df.tail(20)[[\"q_sentence_x\", \"main_codes_x\", \"q_sentence_y\", \"main_codes_y\",\n",
    "         \"cosine_similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cosine_sim_df[(cosine_sim_df[\"main_codes_x\"] == 416) & (cosine_sim_df[\"main_codes_y\"] == 501)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing domain confusion matrix\n",
    "both = cosine_sim_df[(cosine_sim_df[\"main_codes_x\"]>=700) & (cosine_sim_df[\"main_codes_y\"]>=700)].shape[0]\n",
    "all = cosine_sim_df[(cosine_sim_df[\"main_codes_x\"]>=700) | (cosine_sim_df[\"main_codes_y\"]>=700)].shape[0]\n",
    "both/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df[(cosine_sim_df[\"main_codes_x\"]>=700) | (cosine_sim_df[\"main_codes_y\"]>=700)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cosine_sim_df[\"main_codes_x\"]/100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df[\"domain_x\"] = (cosine_sim_df[\"main_codes_x\"]/100).astype(int)\n",
    "cosine_sim_df[\"domain_y\"] = (cosine_sim_df[\"main_codes_y\"]/100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df[\"domain_x\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(cosine_sim_df['domain_x'], cosine_sim_df['domain_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
